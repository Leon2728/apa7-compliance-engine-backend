# APA7 Compliance Engine Backend

Un backend especializado en validaciÃ³n y conformidad con normas APA7 (American Psychological Association, 7Âª ediciÃ³n), desarrollado en **FastAPI**.

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un motor de cumplimiento (compliance engine) para verificar documentos, referencias y citas segÃºn los estÃ¡ndares APA7. Incluye:

- **Motor de reglas**: ValidaciÃ³n flexible basada en reglas configurables
- **Agentes especializados**: MÃ³dulos especÃ­ficos para diferentes tipos de validaciÃ³n
- **Orquestador**: CoordinaciÃ³n de mÃºltiples agentes
- **API REST**: Interfaz HTTP para integraciÃ³n externa

## ğŸš€ Inicio rÃ¡pido

### Requisitos previos

- Python 3.9+
- pip o uv (gestor de paquetes)

### InstalaciÃ³n

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/tu-usuario/apa7-compliance-engine-backend.git
   cd apa7-compliance-engine-backend
   ```

2. **Crear entorno virtual**
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   ```

3. **Instalar dependencias**
   ```bash
   pip install -r requirements.txt
   ```

   O si usas `pyproject.toml`:
   ```bash
   pip install -e .
   ```

### Ejecutar el servidor

```bash
python -m api.main
```

O directamente:
```bash
uvicorn api.main:app --reload
```

El servidor estarÃ¡ disponible en: **`http://localhost:8000`**

Accede a la documentaciÃ³n interactiva en: **`http://localhost:8000/docs`**

## ğŸ§ª Pruebas

Ejecutar todas las pruebas:
```bash
pytest
```

Con cobertura:
```bash
pytest --cov=api tests/
```

## ğŸ“ Estructura del proyecto

```
api/
â”œâ”€â”€ main.py              # AplicaciÃ³n FastAPI principal
â”œâ”€â”€ rules_models.py      # Modelos de datos para reglas
â”œâ”€â”€ rules_library.py     # Biblioteca de reglas APA7
â”œâ”€â”€ agents/              # Agentes especializados
â”œâ”€â”€ orchestrator/        # Orquestador de agentes
â”œâ”€â”€ models/              # Modelos adicionales
â””â”€â”€ rules/
    â””â”€â”€ apa7_cun/        # Reglas especÃ­ficas APA7
tests/                   # Suite de pruebas
```

## ğŸ“š DocumentaciÃ³n

- **API Docs**: `http://localhost:8000/docs` (Swagger)
- **ReDoc**: `http://localhost:8000/redoc`

## ğŸ¤– ConfiguraciÃ³n del LLM (Opcional)

Esta versiÃ³n incluye soporte opcional para integraciÃ³n con modelos de lenguaje (LLM) a travÃ©s de OpenAI. El sistema funciona perfectamente sin LLM habilitado.

### Variables de Entorno

#### LLM_ENABLED
- **Default:** `false`
- **DescripciÃ³n:** Activa o desactiva la funcionalidad de coaching asistido por IA.
- **Valores:** `true`, `false`, `1`, `0`, `yes`, `no`
- **Comportamiento:**
  - `false` â†’ Motor de reglas standard, /coach retorna respuestas genÃ©ricas de fallback
  - `true` â†’ /coach utiliza OpenAI para coaching inteligente (requiere OPENAI_API_KEY)

#### OPENAI_API_KEY
- **Default:** VacÃ­o
- **DescripciÃ³n:** Tu clave API de OpenAI (obtener en https://platform.openai.com/api-keys)
- **Requerido:** SÃ³lo si `LLM_ENABLED=true`
- **Nota de Seguridad:** Nunca comitees esta clave; usa variables de entorno o secrets en CI/CD

#### OPENAI_MODEL
- **Default:** `gpt-4`
- **DescripciÃ³n:** Modelo de OpenAI a utilizar
- **Opciones:** `gpt-4`, `gpt-4-turbo`, `gpt-3.5-turbo`, etc.
- **Requerido:** No (solo cuando LLM_ENABLED=true)

#### OPENAI_TIMEOUT
- **Default:** `30` segundos
- **DescripciÃ³n:** Tiempo mÃ¡ximo de espera para llamadas a OpenAI API
- **Requerido:** No

### Comportamiento Esperado

#### Escenario 1: LLM Deshabilitado (Default)
```bash
LLM_ENABLED=false
```
**Resultado:**
- âœ… App arranca sin problemas
- âœ… /lint funciona (sin cambios)
- âœ… /health funciona (sin cambios)
- âœ… /coach disponible pero retorna respuestas fallback genÃ©ricas
- âœ… Cero dependencias en OpenAI - no requiere OPENAI_API_KEY

#### Escenario 2: LLM Habilitado con Credenciales VÃ¡lidas
```bash
LLM_ENABLED=true
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4
```
**Resultado:**
- âœ… App arranca normalmente
- âœ… /lint funciona (sin cambios)
- âœ… /coach utiliza OpenAI para coaching inteligente
- âœ… Respuestas contextuales y personalizadas por IA

#### Escenario 3: LLM Habilitado pero sin API Key
```bash
LLM_ENABLED=true
OPENAI_API_KEY=  # VacÃ­o
```
**Resultado:**
- âœ… App arranca (degradaciÃ³n elegante)
- âœ… /lint funciona (sin cambios)
- âœ… /coach retorna respuestas fallback (sin errores)
- âœ… Logs indican que LLM no estÃ¡ disponible

### Ejemplo: .env para Desarrollo

```
# SÃ³lo reglas, sin LLM
LLM_ENABLED=false

# O, con LLM en staging/producciÃ³n (ocultar en .gitignore)
# LLM_ENABLED=true
# OPENAI_API_KEY=sk-tu-clave-aqui
# OPENAI_MODEL=gpt-4
# OPENAI_TIMEOUT=30

DEBUG=false
```

### Recomendaciones de Despliegue

1. **Desarrollo Local:** Mantener `LLM_ENABLED=false` para evitar dependencias externas
2. **Testing:** Probar con `LLM_ENABLED=false` primero, luego con `true` en ambiente de staging
3. **ProducciÃ³n:** 
   - âš ï¸ Inicialmente dejar `LLM_ENABLED=false`
   - âœ… Monitorear logs en staging con LLM habilitado
   - âœ… Solo activar en producciÃ³n despuÃ©s de validaciÃ³n exhaustiva
   - âœ… Usar secrets manager para OPENAI_API_KEY
   - âœ… Tener plan de rollback (cambiar flag a false instantÃ¡neamente)

### Endpoints Afectados

- **GET /health** â†’ Sin cambios
- **POST /lint** â†’ Sin cambios (LLM integraciÃ³n futura)
- **POST /coach** â†’ Nuevo; delega a CoachService que usa LLM si estÃ¡ disponible



## ğŸ—ï¸ Arquitectura del backend

Este backend integra un motor de cumplimiento APA7+CUN con soporte opcional para LLM. La arquitectura sigue principios SOLID con clara separaciÃ³n de responsabilidades:

```text
apa7-compliance-engine-backend/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                    # AplicaciÃ³n FastAPI principal
â”‚   â”œâ”€â”€ config.py                  # ConfiguraciÃ³n y feature flags (LLM_ENABLED)
â”‚   â”œâ”€â”€ principal.py               # Punto de entrada de la app
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Exportaciones del mÃ³dulo LLM
â”‚   â”‚   â”œâ”€â”€ client.py              # Interfaz abstracta BaseLLMClient
â”‚   â”‚   â”œâ”€â”€ providers.py           # ImplementaciÃ³n OpenAILLMClient
â”‚   â”‚   â””â”€â”€ prompts/
â”‚   â”‚       â””â”€â”€ coach/
â”‚   â”‚           â””â”€â”€ plan_section_es.md
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ coach_service.py       # Servicio de coaching con LLM
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ __init__.py            # Rutas paquete init
â”‚   â”‚   â””â”€â”€ coach_router.py        # Router del endpoint /coach
â”‚   â”œâ”€â”€ orchestrator/
â”‚   â”‚   â””â”€â”€ lint_orchestrator.py   # Orquestador de agentes
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ coach/
â”‚   â”‚   â””â”€â”€ lint_models.py         # Modelos Pydantic
â”‚   â”œâ”€â”€ agents/                    # Agentes de validaciÃ³n
â”‚   â”œâ”€â”€ rules/                     # Motor de reglas
â”‚   â”‚   â””â”€â”€ apa7_cun/              # Reglas APA7+CUN
â”‚   â””â”€â”€ normas/                    # Normativas y estÃ¡ndares
â”œâ”€â”€ tests/                          # Suite de pruebas
â”œâ”€â”€ docs/                           # DocumentaciÃ³n
â”œâ”€â”€ .env.example                    # Variables de entorno
â”œâ”€â”€ pyproject.toml                  # ConfiguraciÃ³n
â”œâ”€â”€ requirements.txt                # Dependencias
â””â”€â”€ README.md                       # Este archivo
```

### Componentes Clave

- **Motor de Reglas**: ValidaciÃ³n flexible basada en reglas configurables (APA7+CUN)
- **Agentes**: MÃ³dulos independientes para diferentes tipos de validaciÃ³n
- **Orquestador**: Coordina mÃºltiples agentes y ejecuta la lÃ³gica del compliance engine
- **API REST**: Endpoints FastAPI (/lint, /coach, /health)
- **LLM Opcional**: Infraestructura LLM activada con `LLM_ENABLED=true`



## ğŸ¤ Contribuciones

Por favor, lee [CONTRIBUTING.md](./CONTRIBUTING.md) para conocer nuestras directrices.

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia [MIT](./LICENSE).

## ğŸ“§ Contacto

Para preguntas o sugerencias, abre un issue en el repositorio.

---

**Estado**: En desarrollo ğŸš§
